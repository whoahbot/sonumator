{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa \n",
    "import torchaudio\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "\n",
    "from fastai_audio.audio import * \n",
    "\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed for reproducability\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from fastai_audio.audio import SpectrogramConfig, AudioConfig\n",
    "\n",
    "path = Path(\"output/\")\n",
    "\n",
    "sg_cfg = SpectrogramConfig(\n",
    "    f_min=200.0,\n",
    "    f_max=1000.0,\n",
    "    hop_length=32,\n",
    "    n_fft=128,\n",
    "    n_mels=64,\n",
    "    pad=0,\n",
    "    win_length=None\n",
    ")\n",
    "\n",
    "config = AudioConfig(\n",
    "    use_spectro=True,\n",
    "    #delta=True,\n",
    "    sg_cfg=sg_cfg,\n",
    ")\n",
    "\n",
    "al = AudioList.from_folder(path, config=config).split_by_rand_pct(.2, seed=4).label_from_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = None\n",
    "#tfms = get_spectro_transforms(mask_time=False, mask_freq=True, roll=False, num_rows=12)\n",
    "tfms = get_spectro_transforms(\n",
    "    size=(128, 626), # Upscale the spectrograms from 64x313\n",
    "    mask_frequency=False, # Don't mask frequencies\n",
    "    mask_time=False # Don't mask time\n",
    ")\n",
    "db = al.transform(tfms).databunch(bs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import models\n",
    "\n",
    "from fastai_audio.audio import *\n",
    "\n",
    "learn = audio_learner(db, base_arch=models.resnet50)\n",
    "learn = learn.load(\"weight_decay_more_data_465\")\n",
    "learn.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category damselfish"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check that our model can identify samples we trained it on\n",
    "tmpfile=\"output/damselfish/20.wav\"\n",
    "item = AudioItem(path=tmpfile)\n",
    "(category, _, _) = audio_predict(learn, item)\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call, check_output\n",
    "\n",
    "def fetch_recording(gs_path):\n",
    "  return_code = call([\"gsutil\", \"cp\", gs_path, \"recordings/\"])\n",
    "  print(return_code)\n",
    "\n",
    "def list_all_recordings():\n",
    "  return check_output([\"gsutil\", \"ls\", \"gs://sonumator/recordings/2015-2016/*.wav\"]).decode(\"utf-8\").splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "def search_file_for_samples(gs_filepath, model, offset=2):\n",
    "    fetch_recording(gs_filepath)\n",
    "    filepath = f\"recordings/{os.path.basename(gs_filepath)}\"\n",
    "    df = pd.DataFrame(columns=[\"start\", \"end\", \"filepath\"])\n",
    "\n",
    "    si, ei = torchaudio.info(filepath)\n",
    "    length = si.length / si.rate\n",
    "\n",
    "    for i in range(0, int(length), offset):\n",
    "        end = i + offset\n",
    "        \n",
    "        basename = os.path.basename(filepath)[:-4]\n",
    "\n",
    "        y, sr = librosa.load(\n",
    "            filepath,\n",
    "            sr=5000,\n",
    "            offset=i,\n",
    "            duration=2,\n",
    "        )\n",
    "        tmpfile = f\"potentials/{basename}-{i}.wav\"\n",
    "        sf.write(tmpfile, y, 5000)\n",
    "        item = AudioItem(path=tmpfile)\n",
    "        category, _, _ = audio_predict(learn, item)\n",
    "        if str(category) == \"damselfish\":\n",
    "            df = df.append([{\"start\": i, \"end\": end, \"filepath\": filepath}])\n",
    "        os.remove(tmpfile)\n",
    "    \n",
    "    os.remove(filepath)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = list_all_recordings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def search_all_files(file_list):\n",
    "    completed_dataframes = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        future_to_df = {executor.submit(search_file_for_samples, gs_filepath, learn): gs_filepath for gs_filepath in file_list}\n",
    "        for future in concurrent.futures.as_completed(future_to_df):\n",
    "            url = future_to_df[future]\n",
    "            try:\n",
    "                df = future.result()\n",
    "            except Exception as exc:\n",
    "                print('%r generated an exception: %s' % (url, exc))\n",
    "            else:\n",
    "                completed_dataframes.append(df)\n",
    "\n",
    "    return pd.concat(completed_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "df = search_all_files(all_files[0:4])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
